{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a6e174-508e-4658-98ec-62ebd4cef0e7",
   "metadata": {},
   "source": [
    "<font size=6><b>Lec00. LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7592b2c-5ef4-4510-89be-b1e540ad4e38",
   "metadata": {},
   "source": [
    "* Examples of LSTM models in Python:\n",
    "https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/ \n",
    "* Useful tutorial for timeseries forecasting: \n",
    "https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/\n",
    "* Open source “Gluon-TS”. You can use DeepAR model for forecasting if you want an LSTM solution: \n",
    "https://github.com/awslabs/gluon-ts \n",
    "* Book that explains forecasting principles:\n",
    "https://otexts.com/fpp2/ \n",
    "\n",
    "<pre>\n",
    "Univariate LSTM Models\n",
    "        Data set\n",
    "        Vanilla LSTM\n",
    "        Stacked LSTM\n",
    "        Bidirectional LSTM\n",
    "        CNN LSTM\n",
    "        ConvLSTM\n",
    "Multivariate LSTM Models\n",
    "        Multiple Input Series.\n",
    "        Multiple Parallel Series.\n",
    "Multi-Step LSTM Models\n",
    "        Data Preparation\n",
    "        Vector Output Model\n",
    "        Encoder-Decoder Model\n",
    "Multivariate Multi-Step LSTM Models\n",
    "        Multiple Input Multi-Step Output.\n",
    "        Multiple Parallel Input and Multi-Step Output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe67037-19e0-491b-befd-07a34dae10ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "    \n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "#-------------------- 주피터 , 출력결과 넓이 늘리기 ---------------\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container{width:100% !important;}</style>\"))\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b34dd8a-77c9-4722-9427-80300e123213",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72fff8a-4bee-45fc-b2d8-d301f9945d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_list = [] \n",
    "# compare_df = pd.DataFrame(compare_list, columns=[\"model_type\",\"model\",\"dim\", \"X\",\"y\", \"mse\"])\n",
    "# compare_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed450ba1-3d44-4fa3-ba96-e8949c7b21b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS__   = 300\n",
    "PATIENCE__ = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2cd54a-d07d-4848-9f6d-91ed39b1af7a",
   "metadata": {},
   "source": [
    "# Univariate LSTM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d447b45-6717-4ce0-8eed-a55268460534",
   "metadata": {},
   "source": [
    "## Data set\n",
    "\n",
    "<pre>\n",
    "[10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "\n",
    "X,\t\t\ty\n",
    "10, 20, 30\t\t40\n",
    "20, 30, 40\t\t50\n",
    "30, 40, 50\t\t60\n",
    "...\n",
    "60, 70, 80\t\t90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29488005-0294-4418-91b1-3eeb5e064970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3) (6,)\n",
      "[10 20 30] 40\n",
      "------------------\n",
      "[20 30 40] 50\n",
      "------------------\n",
      "[30 40 50] 60\n",
      "------------------\n",
      "[40 50 60] 70\n",
      "------------------\n",
      "[50 60 70] 80\n",
      "------------------\n",
      "[60 70 80] 90\n",
      "------------------\n",
      "(6, 3, 1) (6,)\n"
     ]
    }
   ],
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    " \n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "n_steps = 3\n",
    "\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])\n",
    "    print(\"------------------\")\n",
    "    \n",
    "# reshape : [samples, timesteps] --> [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72451d0-f030-4157-bdac-0b99e0995a46",
   "metadata": {},
   "source": [
    "<img src=\"https://wikidocs.net/images/page/22886/rnn_image6between7.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ba3842-7567-4b05-8bda-2c80a1b918c3",
   "metadata": {},
   "source": [
    "## Vanilla LSTM \n",
    "* <font color=red><b>[samples, timesteps, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f67afba2-30d0-467b-a51a-bf4bf9b0851f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3, 1) (6,)\n",
      "[[10]\n",
      " [20]\n",
      " [30]] 40\n",
      "------------------\n",
      "[[20]\n",
      " [30]\n",
      " [40]] 50\n",
      "------------------\n",
      "[[30]\n",
      " [40]\n",
      " [50]] 60\n",
      "------------------\n",
      "[[40]\n",
      " [50]\n",
      " [60]] 70\n",
      "------------------\n",
      "[[50]\n",
      " [60]\n",
      " [70]] 80\n",
      "------------------\n",
      "[[60]\n",
      " [70]\n",
      " [80]] 90\n",
      "------------------\n",
      "[[[70]\n",
      "  [80]\n",
      "  [90]]]\n",
      "[[101.01401]]\n",
      "MSE : : 1.0282\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "#-------------------------------------------------------------\n",
    "stop = EarlyStopping(monitor='loss', patience=PATIENCE__)\n",
    "model.fit(X, y, epochs=EPOCHS__, verbose=0,  callbacks=[stop])\n",
    "\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])\n",
    "    print(\"------------------\")\n",
    "    \n",
    "x_input = array([70, 80, 90]).reshape((1, n_steps, n_features))  #[samples, timesteps, features]\n",
    "print(x_input)\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n",
    "\n",
    "test_y = np.array([[100]])\n",
    "mse = f\"{mean_squared_error(test_y, yhat):.4f}\"\n",
    "print(f\"MSE : : {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00d77b9c-d26d-43ca-b426-b625c07d07f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_str = '[samples, timesteps, features]'\n",
    "compare_list.append(['Univariate LSTM Models', 'Vanilla LSTM',dim_str,x_input, yhat, mse])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fa4991-1698-4305-b0e3-462c5916d3e8",
   "metadata": {},
   "source": [
    "## Stacked LSTM \n",
    "* [samples, timesteps, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2527391f-262f-407d-81d3-e1c6a1996a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3, 1) (6,)\n",
      "[[10]\n",
      " [20]\n",
      " [30]] 40\n",
      "------------------\n",
      "[[20]\n",
      " [30]\n",
      " [40]] 50\n",
      "------------------\n",
      "[[30]\n",
      " [40]\n",
      " [50]] 60\n",
      "------------------\n",
      "[[40]\n",
      " [50]\n",
      " [60]] 70\n",
      "------------------\n",
      "[[50]\n",
      " [60]\n",
      " [70]] 80\n",
      "------------------\n",
      "[[60]\n",
      " [70]\n",
      " [80]] 90\n",
      "------------------\n",
      "[[103.255325]]\n",
      "MSE : : 10.5971\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "#-------------------------------------------------------------\n",
    "stop = EarlyStopping(monitor='loss', patience=PATIENCE__)\n",
    "model.fit(X, y, epochs=EPOCHS__, verbose=0,  callbacks=[stop])\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])\n",
    "    print(\"------------------\")\n",
    "    \n",
    "x_input = array([70, 80, 90]).reshape((1, n_steps, n_features))  #[samples, timesteps, features]\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n",
    "\n",
    "test_y = np.array([[100]])\n",
    "mse = f\"{mean_squared_error(test_y, yhat):.4f}\"\n",
    "print(f\"MSE : : {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15b2772d-be4a-401d-9b85-3c5ee31627c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_str = '[samples, timesteps, features]'\n",
    "compare_list.append(['Univariate LSTM Models', 'Stacked LSTM',dim_str,x_input, yhat, mse])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c14fd6-57a4-41c5-813c-804b0ae8399c",
   "metadata": {},
   "source": [
    "## ★Bidirectional LSTM \n",
    "* [samples, timesteps, features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ac876af-26a1-4331-81bf-5a9dad26a6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5ac8c89-8d02-4730-90fd-a4417b5c541c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3, 1) (6,)\n",
      "[[10]\n",
      " [20]\n",
      " [30]] 40\n",
      "------------------\n",
      "[[20]\n",
      " [30]\n",
      " [40]] 50\n",
      "------------------\n",
      "[[30]\n",
      " [40]\n",
      " [50]] 60\n",
      "------------------\n",
      "[[40]\n",
      " [50]\n",
      " [60]] 70\n",
      "------------------\n",
      "[[50]\n",
      " [60]\n",
      " [70]] 80\n",
      "------------------\n",
      "[[60]\n",
      " [70]\n",
      " [80]] 90\n",
      "------------------\n",
      "[[100.12335]]\n",
      "MSE : : 0.0152\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "#-------------------------------------------------------------\n",
    "stop = EarlyStopping(monitor='loss', patience=PATIENCE__)\n",
    "model.fit(X, y, epochs=EPOCHS__, verbose=0,  callbacks=[stop])\n",
    "\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])\n",
    "    print(\"------------------\")\n",
    "    \n",
    "x_input = array([70, 80, 90]).reshape((1, n_steps, n_features))  #[samples, timesteps, features]\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n",
    "\n",
    "test_y = np.array([[100]])\n",
    "mse = f\"{mean_squared_error(test_y, yhat):.4f}\"\n",
    "print(f\"MSE : : {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d881c306-fe2f-4467-b39d-2493949ae714",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_str = '[samples, timesteps, features]'\n",
    "compare_list.append(['Univariate LSTM Models', 'Bidirectional LSTM',dim_str,x_input, yhat, mse])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a6429f-9c43-42dd-9232-16ce3f9a94d9",
   "metadata": {},
   "source": [
    "## ★CNN LSTM \n",
    "* <font color=red><b>[samples, subsequences, timesteps, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "606f28e6-37cf-4639-8f59-1d50f8bfc773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc74e997-7a60-42e3-93e8-98f1cc013c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30 40] 50\n",
      "------------------\n",
      "[20 30 40 50] 60\n",
      "------------------\n",
      "[30 40 50 60] 70\n",
      "------------------\n",
      "[40 50 60 70] 80\n",
      "------------------\n",
      "[50 60 70 80] 90\n",
      "------------------\n",
      "(5, 4) (5,)\n"
     ]
    }
   ],
   "source": [
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "n_steps = 4\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])\n",
    "    print(\"------------------\")\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9479577e-fea4-41d5-832d-84d39d8f0645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2, 2, 1) (5,)\n",
      "[[[10]\n",
      "  [20]]\n",
      "\n",
      " [[30]\n",
      "  [40]]] 50\n",
      "------------------\n",
      "[[[20]\n",
      "  [30]]\n",
      "\n",
      " [[40]\n",
      "  [50]]] 60\n",
      "------------------\n",
      "[[[30]\n",
      "  [40]]\n",
      "\n",
      " [[50]\n",
      "  [60]]] 70\n",
      "------------------\n",
      "[[[40]\n",
      "  [50]]\n",
      "\n",
      " [[60]\n",
      "  [70]]] 80\n",
      "------------------\n",
      "[[[50]\n",
      "  [60]]\n",
      "\n",
      " [[70]\n",
      "  [80]]] 90\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# reshape : [samples, timesteps] -->  [samples, subsequences, timesteps, features]\n",
    "n_subseq   = 2\n",
    "n_steps    = 2\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], n_subseq, n_steps, n_features))\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])\n",
    "    print(\"------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a667aa1e-fc35-44c5-ad7d-ca9139ee5161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101.11435]]\n",
      "MSE : : 1.2418\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "#-------------------------------------------------------------\n",
    "stop = EarlyStopping(monitor='loss', patience=PATIENCE__)\n",
    "model.fit(X, y, epochs=EPOCHS__, verbose=0,  callbacks=[stop])\n",
    "\n",
    "x_input = array([60, 70, 80, 90]).reshape((1, n_subseq, n_steps, n_features)) #2, 2, 1\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n",
    "\n",
    "test_y = np.array([[100]])\n",
    "mse = f\"{mean_squared_error(test_y, yhat):.4f}\"\n",
    "print(f\"MSE : : {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ba07fec-af29-422d-bed0-318122afbb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_str = '[samples, subsequences, timesteps, features]'\n",
    "compare_list.append(['Univariate LSTM Models', 'CNN LSTM',dim_str,x_input, yhat, mse])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729a58d4-23b8-427f-9485-60d2ed5f0a08",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ConvLSTM \n",
    "* <font color=red><b>[samples, timesteps, rows, columns, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1b19bf9-539a-4db9-919a-da05c3301495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import ConvLSTM2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bfed561-1aaa-4047-85cb-512c11f5501b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30 40] 50\n",
      "------------------\n",
      "[20 30 40 50] 60\n",
      "------------------\n",
      "[30 40 50 60] 70\n",
      "------------------\n",
      "[40 50 60 70] 80\n",
      "------------------\n",
      "[50 60 70 80] 90\n",
      "------------------\n",
      "(5, 4) (5,)\n"
     ]
    }
   ],
   "source": [
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "n_steps = 4\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])\n",
    "    print(\"------------------\")\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a16d5e86-3d49-4f31-9df5-933a4cc2356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2, 1, 2, 1) (5,)\n",
      "[[[[10]\n",
      "   [20]]]\n",
      "\n",
      "\n",
      " [[[30]\n",
      "   [40]]]] 50\n",
      "------------------\n",
      "[[[[20]\n",
      "   [30]]]\n",
      "\n",
      "\n",
      " [[[40]\n",
      "   [50]]]] 60\n",
      "------------------\n",
      "[[[[30]\n",
      "   [40]]]\n",
      "\n",
      "\n",
      " [[[50]\n",
      "   [60]]]] 70\n",
      "------------------\n",
      "[[[[40]\n",
      "   [50]]]\n",
      "\n",
      "\n",
      " [[[60]\n",
      "   [70]]]] 80\n",
      "------------------\n",
      "[[[[50]\n",
      "   [60]]]\n",
      "\n",
      "\n",
      " [[[70]\n",
      "   [80]]]] 90\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# reshape : [samples, timesteps] --> [samples, timesteps, rows, columns, features]\n",
    "n_seq      = 2\n",
    "n_steps    = 2\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], n_seq, 1, n_steps, n_features))\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])\n",
    "    print(\"------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53812753-abf8-465b-9388-b796f6b49340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F87D81CB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[104.403595]]\n",
      "MSE : : 19.3916\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------\n",
    "model = Sequential()\n",
    "# [samples, timesteps, rows, columns, features]\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(n_seq, 1, n_steps, n_features))) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "#-------------------------------------------------------------\n",
    "stop = EarlyStopping(monitor='loss', patience=PATIENCE__)\n",
    "model.fit(X, y, epochs=EPOCHS__, verbose=0,  callbacks=[stop])\n",
    "\n",
    "\n",
    "x_input = array([60, 70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_seq, 1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n",
    "\n",
    "test_y = np.array([[100]])\n",
    "mse = f\"{mean_squared_error(test_y, yhat):.4f}\"\n",
    "print(f\"MSE : : {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f8c5552-4063-499e-8015-4dfcac6038bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_str = '[samples, timesteps, rows, columns, features]'\n",
    "compare_list.append(['Univariate LSTM Models', 'ConvLSTM',dim_str,x_input, yhat, mse])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369fd644-1f5d-49d2-9ebf-a563ffa7ee1e",
   "metadata": {},
   "source": [
    "# Multivariate LSTM Models\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9f75ab-4be1-4235-a52a-1e839718925e",
   "metadata": {},
   "source": [
    "## Data set\n",
    "\n",
    "<pre>\n",
    "[10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "[15, 25, 35, 45, 55, 65, 75, 85, 95]\n",
    "\n",
    "[[ 10  15  25]\n",
    " [ 20  25  45]\n",
    " [ 30  35  65]\n",
    " [ 40  45  85]\n",
    " [ 50  55 105]\n",
    " [ 60  65 125]\n",
    " [ 70  75 145]\n",
    " [ 80  85 165]\n",
    " [ 90  95 185]]\n",
    "\n",
    "\n",
    "X,\t\ty\n",
    "10, 15\n",
    "20, 25\n",
    "30, 35\t\t65\n",
    "\n",
    "20, 25\n",
    "30, 35\n",
    "40, 45\t\t85\n",
    "...\n",
    "70, 75\n",
    "80, 85\n",
    "90, 95\t\t185"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91932ed6-84d5-441f-b8c2-225c0248d6fd",
   "metadata": {},
   "source": [
    "## ★MultipleInput Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8df2390-b13c-4df8-8dfa-c2d3aa19de22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10  15  25]\n",
      " [ 20  25  45]\n",
      " [ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import hstack\n",
    "\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "\n",
    "# [rows, columns] \n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34aef388-131a-46aa-82a1-badffaca5d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30d27082-c212-4b9b-8029-a394056d24a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 3, 2) (7,)\n",
      "[[10 15]\n",
      " [20 25]\n",
      " [30 35]] 65\n",
      "------------------\n",
      "[[20 25]\n",
      " [30 35]\n",
      " [40 45]] 85\n",
      "------------------\n",
      "[[30 35]\n",
      " [40 45]\n",
      " [50 55]] 105\n",
      "------------------\n",
      "[[40 45]\n",
      " [50 55]\n",
      " [60 65]] 125\n",
      "------------------\n",
      "[[50 55]\n",
      " [60 65]\n",
      " [70 75]] 145\n",
      "------------------\n",
      "[[60 65]\n",
      " [70 75]\n",
      " [80 85]] 165\n",
      "------------------\n",
      "[[70 75]\n",
      " [80 85]\n",
      " [90 95]] 185\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "n_steps = 3    #timesteps\n",
    "X, y = split_sequences(dataset, n_steps)\n",
    "print(X.shape, y.shape)\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f60c9067-95c0-49ab-ba84-7418c1e5e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0675e266-c1e5-413c-94ab-8461493a878c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F80D5DB790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[205.16708]]\n",
      "MSE : : 0.0279\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "#-------------------------------------------------------------\n",
    "stop = EarlyStopping(monitor='loss', patience=PATIENCE__)\n",
    "model.fit(X, y, epochs=EPOCHS__, verbose=0,  callbacks=[stop])\n",
    "\n",
    "\n",
    "x_input = array([[80, 85], [90, 95], [100, 105]]).reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n",
    "\n",
    "test_y = np.array([[205]])\n",
    "mse = f\"{mean_squared_error(test_y, yhat):.4f}\"\n",
    "print(f\"MSE : : {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64086d82-141c-4727-bef1-8654ee2cbdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_str=\"[rows, columns]\"\n",
    "compare_list.append(['Multivariate LSTM Models','Multiple Input Series',dim_str,x_input, yhat, mse])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38124a7c-2dbd-40c8-b9c1-441478fb1e40",
   "metadata": {},
   "source": [
    "## ★MultipleParallel Series\n",
    "<pre>\n",
    "X : \n",
    "10, 15, 25\n",
    "20, 25, 45\n",
    "30, 35, 65\n",
    "\n",
    "y :\n",
    "40, 45, 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0bedec3-dce2-40c4-91fd-9c6da39ff6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10  15  25]\n",
      " [ 20  25  45]\n",
      " [ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e42574a-9bdb-402f-8116-ec10b8ac1ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequences)-1:\n",
    "            break\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cb50fc7-39b7-4756-8f44-3060a9f80d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3, 3) (6, 3)\n",
      "[[10 15 25]\n",
      " [20 25 45]\n",
      " [30 35 65]] [40 45 85]\n",
      "------------------\n",
      "[[20 25 45]\n",
      " [30 35 65]\n",
      " [40 45 85]] [ 50  55 105]\n",
      "------------------\n",
      "[[ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]] [ 60  65 125]\n",
      "------------------\n",
      "[[ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]] [ 70  75 145]\n",
      "------------------\n",
      "[[ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]] [ 80  85 165]\n",
      "------------------\n",
      "[[ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]] [ 90  95 185]\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "n_steps = 3\n",
    "X, y = split_sequences(dataset, n_steps)\n",
    "print(X.shape, y.shape)\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67b9232e-3508-462b-b1fd-831dc2b964e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 70  75 145]\n",
      "  [ 80  85 165]\n",
      "  [ 90  95 185]]]\n",
      "[[100.68982 106.199   204.83968]]\n",
      "MSE : : 0.6464\n"
     ]
    }
   ],
   "source": [
    "n_features = X.shape[2]\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(n_features))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "#-------------------------------------------------------------\n",
    "stop = EarlyStopping(monitor='loss', patience=PATIENCE__)\n",
    "model.fit(X, y, epochs=EPOCHS__, verbose=0,  callbacks=[stop])\n",
    "\n",
    "\n",
    "x_input = array([[70,75,145], [80,85,165], [90,95,185]]).reshape((1, n_steps, n_features))\n",
    "print(x_input)\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n",
    " \n",
    "test_y = np.array([[100, 105, 205]])\n",
    "mse = f\"{mean_squared_error(test_y, yhat):.4f}\"\n",
    "print(f\"MSE : : {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b4b37d0-4cbe-4e44-8997-2e093bc9d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_str=\"[rows, columns]\"\n",
    "compare_list.append(['Multivariate LSTM Models','Multiple Parallel Series',dim_str,x_input, yhat, mse])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6599ecc1-d7fc-42ef-b7d5-3d67283dd788",
   "metadata": {},
   "source": [
    "# Multi-Step LSTM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094a0f0d-3d7d-46ce-9ff4-8935aafe651d",
   "metadata": {},
   "source": [
    "## Data set\n",
    "\n",
    "<pre>\n",
    "[10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "\n",
    "X,\t\t\ty\n",
    "10, 20, 30\t\t40 50\n",
    "20, 30, 40\t\t50 60\n",
    "30, 40, 50\t\t60 70\n",
    "...\n",
    "50, 60, 70\t\t80 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20a9ca9b-a8b1-469e-8308-055d9463cbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30] [40 50]\n",
      "------------------\n",
      "[20 30 40] [50 60]\n",
      "------------------\n",
      "[30 40 50] [60 70]\n",
      "------------------\n",
      "[40 50 60] [70 80]\n",
      "------------------\n",
      "[50 60 70] [80 90]\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    " \n",
    "\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be238fb3-cd51-4051-96bd-3b5114ce8c81",
   "metadata": {},
   "source": [
    "## Vector Output Model\n",
    "\n",
    "<pre>\n",
    "X : [70, 80, 90]\n",
    "y : [100,110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed1f8a51-159f-4978-b28c-2b3876e7bf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3, 1) (5, 2)\n",
      "[[10]\n",
      " [20]\n",
      " [30]] [40 50]\n",
      "------------------\n",
      "[[20]\n",
      " [30]\n",
      " [40]] [50 60]\n",
      "------------------\n",
      "[[30]\n",
      " [40]\n",
      " [50]] [60 70]\n",
      "------------------\n",
      "[[40]\n",
      " [50]\n",
      " [60]] [70 80]\n",
      "------------------\n",
      "[[50]\n",
      " [60]\n",
      " [70]] [80 90]\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# shape : [samples, timesteps] --> [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "print(X.shape, y.shape)\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "372a9328-3255-44e7-873c-16c14499eb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104.01215 116.03949]]\n",
      "MSE : : 26.2864\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "#-------------------------------------------------------------\n",
    "stop = EarlyStopping(monitor='loss', patience=PATIENCE__)\n",
    "model.fit(X, y, epochs=EPOCHS__, verbose=0,  callbacks=[stop])\n",
    "\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n",
    "\n",
    "test_y = np.array([[100, 110]])\n",
    "mse = f\"{mean_squared_error(test_y, yhat):.4f}\"\n",
    "print(f\"MSE : : {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7670bdc2-bd41-4bc1-8159-0fd6ee55be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_str = \"[samples, timesteps, features]\"\n",
    "compare_list.append(['Multi-Step LSTM Models','Vector Output',dim_str,x_input, yhat, mse])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbad4ee0-037b-4015-b7ca-b9dcefe167e9",
   "metadata": {},
   "source": [
    "## Encoder-Decoder Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04aa5b95-9ae9-4bb5-8de7-48e920e57c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ff725b6-a978-4c42-b1b5-5ff003a936b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3, 1) (5, 2, 1)\n",
      "[[10]\n",
      " [20]\n",
      " [30]] [[40]\n",
      " [50]]\n",
      "------------------\n",
      "[[20]\n",
      " [30]\n",
      " [40]] [[50]\n",
      " [60]]\n",
      "------------------\n",
      "[[30]\n",
      " [40]\n",
      " [50]] [[60]\n",
      " [70]]\n",
      "------------------\n",
      "[[40]\n",
      " [50]\n",
      " [60]] [[70]\n",
      " [80]]\n",
      "------------------\n",
      "[[50]\n",
      " [60]\n",
      " [70]] [[80]\n",
      " [90]]\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# shape : [samples, timesteps] --> [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "y = y.reshape((y.shape[0], y.shape[1], n_features))\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71b80866-0025-4ce0-880b-ddf48e4c3850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[101.36606]\n",
      "  [114.12388]]]\n",
      "MSE : : 9.4362\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "model.add(RepeatVector(n_steps_out))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "#-------------------------------------------------------------\n",
    "stop = EarlyStopping(monitor='loss', patience=PATIENCE__)\n",
    "model.fit(X, y, epochs=EPOCHS__, verbose=0,  callbacks=[stop])\n",
    "\n",
    "\n",
    "x_input = array([70, 80, 90]).reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n",
    "\n",
    "# -------------- Estimator expected <= 2 dim -------------------\n",
    "yhat2 = yhat.reshape(-1,1)\n",
    "test_y = np.array( [[100],[110]]  )\n",
    "mse = f\"{mean_squared_error(test_y, yhat2):.4f}\"\n",
    "print(f\"MSE : : {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a5452f5-b892-40aa-a963-2cc2a903b205",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_str = \"[samples, timesteps, features]\"\n",
    "compare_list.append(['Multi-Step LSTM Models','Encoder-Decoder',dim_str,x_input, yhat, mse])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c602582f-bd9e-4644-9a87-342c35d72320",
   "metadata": {},
   "source": [
    "# Multivariate Multi-Step LSTM Models\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddab6e8-e8b4-4f09-ac48-af39fff21fa9",
   "metadata": {},
   "source": [
    "## Data set\n",
    "\n",
    "<pre>\n",
    "[10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "[15, 25, 35, 45, 55, 65, 75, 85, 95]\n",
    "\n",
    "[[ 10  15  25]\n",
    " [ 20  25  45]\n",
    " [ 30  35  65]\n",
    " [ 40  45  85]\n",
    " [ 50  55 105]\n",
    " [ 60  65 125]\n",
    " [ 70  75 145]\n",
    " [ 80  85 165]\n",
    " [ 90  95 185]]\n",
    "\n",
    "\n",
    "X,\t\ty\n",
    "10, 15\n",
    "20, 25\n",
    "30, 35\t\t65, 85\n",
    "\n",
    "20, 25\n",
    "30, 35\n",
    "40, 45\t\t85, 105\n",
    "...\n",
    "60, 65\n",
    "70, 75\n",
    "80, 85\t\t165, 185"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a3001a6-bc8c-4542-bcc9-301731a72e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e785445-1227-4a77-aceb-f62ec1cfc600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10,  15,  25],\n",
       "       [ 20,  25,  45],\n",
       "       [ 30,  35,  65],\n",
       "       [ 40,  45,  85],\n",
       "       [ 50,  55, 105],\n",
       "       [ 60,  65, 125],\n",
       "       [ 70,  75, 145],\n",
       "       [ 80,  85, 165],\n",
       "       [ 90,  95, 185]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define input sequence\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# [rows, columns] \n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2da2018-9492-4da3-b91f-6a1a5cb07bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3, 2) (6, 2)\n",
      "[[10 15]\n",
      " [20 25]\n",
      " [30 35]] [65 85]\n",
      "------------------\n",
      "[[20 25]\n",
      " [30 35]\n",
      " [40 45]] [ 85 105]\n",
      "------------------\n",
      "[[30 35]\n",
      " [40 45]\n",
      " [50 55]] [105 125]\n",
      "------------------\n",
      "[[40 45]\n",
      " [50 55]\n",
      " [60 65]] [125 145]\n",
      "------------------\n",
      "[[50 55]\n",
      " [60 65]\n",
      " [70 75]] [145 165]\n",
      "------------------\n",
      "[[60 65]\n",
      " [70 75]\n",
      " [80 85]] [165 185]\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "n_steps_in, n_steps_out = 3, 2\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "print(X.shape, y.shape)\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6fbcbf-1ab3-411e-ac47-bb4ae6a763ec",
   "metadata": {},
   "source": [
    "## Multiple Input Multi-Step Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b602a57-90fc-4a6d-b4b5-6950b0f9242e",
   "metadata": {},
   "source": [
    "<pre>\n",
    "X,\t\ty\n",
    "10, 15\n",
    "20, 25\n",
    "30, 35\t\t65, 85\n",
    "\n",
    "20, 25\n",
    "30, 35\n",
    "40, 45\t\t85, 105\n",
    "...\n",
    "60, 65\n",
    "70, 75\n",
    "80, 85\t\t165, 185"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26b30f54-8662-42d9-9fc1-08c3624f079a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[186.0647  206.36623]]\n",
      "MSE : : 1.5001\n"
     ]
    }
   ],
   "source": [
    "n_features = X.shape[2]\n",
    "#-------------------------------------------------------------\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "#-------------------------------------------------------------\n",
    "stop = EarlyStopping(monitor='loss', patience=PATIENCE__)\n",
    "model.fit(X, y, epochs=EPOCHS__, verbose=0,  callbacks=[stop])\n",
    "\n",
    "\n",
    "x_input = array([[70, 75], [80, 85], [90, 95]]).reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n",
    "\n",
    "test_y = np.array( [[185,205]]  )\n",
    "mse = f\"{mean_squared_error(test_y, yhat):.4f}\"\n",
    "print(f\"MSE : : {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f2c2d10-348a-40a0-a0da-a20677bb174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_str=\"[rows, columns]\"\n",
    "compare_list.append(['Multivariate Multi-Step LSTM Models','Multiple Input Multi-Step Output',dim_str,x_input, yhat, mse])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facc4d10-f186-478d-83e1-e472ea1bf7de",
   "metadata": {},
   "source": [
    "## Multiple Parallel Input and Multi-Step Output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676ad5ca-cba9-4586-92ea-6d5a587ccf1d",
   "metadata": {},
   "source": [
    "<pre>\n",
    "X : \n",
    "10, 15, 25\n",
    "20, 25, 45\n",
    "30, 35, 65\n",
    "\n",
    "y : \n",
    "40, 45, 85\n",
    "50, 55, 105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1885625-5f9b-438e-b68c-77948824db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b4371df-a5c7-40b2-b370-d1a26a003165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10,  15,  25],\n",
       "       [ 20,  25,  45],\n",
       "       [ 30,  35,  65],\n",
       "       [ 40,  45,  85],\n",
       "       [ 50,  55, 105],\n",
       "       [ 60,  65, 125],\n",
       "       [ 70,  75, 145],\n",
       "       [ 80,  85, 165],\n",
       "       [ 90,  95, 185]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d276ed3b-618d-4709-9a88-cb0a71598129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3, 3) (5, 2, 3)\n",
      "[[10 15 25]\n",
      " [20 25 45]\n",
      " [30 35 65]] [[ 40  45  85]\n",
      " [ 50  55 105]]\n",
      "------------------\n",
      "[[20 25 45]\n",
      " [30 35 65]\n",
      " [40 45 85]] [[ 50  55 105]\n",
      " [ 60  65 125]]\n",
      "------------------\n",
      "[[ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]] [[ 60  65 125]\n",
      " [ 70  75 145]]\n",
      "------------------\n",
      "[[ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]] [[ 70  75 145]\n",
      " [ 80  85 165]]\n",
      "------------------\n",
      "[[ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]] [[ 80  85 165]\n",
      " [ 90  95 185]]\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "n_steps_in, n_steps_out = 3, 2\n",
    "# covert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "print(X.shape, y.shape)\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca4c03f9-91d7-4dbd-a9e6-df422cb3e513",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 90.265816  95.88     185.84712 ]\n",
      "  [100.86708  105.51342  206.3824  ]]]\n",
      "[[ 90.265816]\n",
      " [ 95.88    ]\n",
      " [185.84712 ]\n",
      " [100.86708 ]\n",
      " [105.51342 ]\n",
      " [206.3824  ]]\n",
      "MSE : : 0.7482\n"
     ]
    }
   ],
   "source": [
    "n_features = X.shape[2]\n",
    "#-------------------------------------------------------------\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "model.add(RepeatVector(n_steps_out))\n",
    "model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_features)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "#-------------------------------------------------------------\n",
    "stop = EarlyStopping(monitor='loss', patience=PATIENCE__)\n",
    "model.fit(X, y, epochs=EPOCHS__, verbose=0,  callbacks=[stop])\n",
    "\n",
    "\n",
    "x_input = array([[60, 65, 125], [70, 75, 145], [80, 85, 165]]).reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n",
    "\n",
    "# -------------- Estimator expected <= 2 dim -------------------\n",
    "yhat2 = yhat.reshape(-1,1)\n",
    "print(yhat2)\n",
    "\n",
    "\n",
    "test_y = np.array( [[ 90], [95], [185], [100], [105], [205]] )\n",
    "mse = f\"{mean_squared_error(test_y, yhat2):.4f}\"\n",
    "print(f\"MSE : : {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d5d037e4-dadf-43e9-894f-8756d7a99dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_str=\"[rows, columns]\"\n",
    "compare_list.append(['Multivariate Multi-Step LSTM Models','Multiple Parallel Input and Multi-Step Output',dim_str,x_input, yhat, mse])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eff3a5-3b8d-4a89-afc6-b484f07869e1",
   "metadata": {},
   "source": [
    "# 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e464352-49bf-4b2b-8bb4-240078bd6417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>dim</th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bidirectional LSTM</th>\n",
       "      <td>Univariate LSTM Models</td>\n",
       "      <td>[samples, timesteps, features]</td>\n",
       "      <td>[[[70], [80], [90]]]</td>\n",
       "      <td>[[100.12335]]</td>\n",
       "      <td>0.0152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multiple Input Series</th>\n",
       "      <td>Multivariate LSTM Models</td>\n",
       "      <td>[rows, columns]</td>\n",
       "      <td>[[[80, 85], [90, 95], [100, 105]]]</td>\n",
       "      <td>[[205.16708]]</td>\n",
       "      <td>0.0279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multiple Parallel Series</th>\n",
       "      <td>Multivariate LSTM Models</td>\n",
       "      <td>[rows, columns]</td>\n",
       "      <td>[[[70, 75, 145], [80, 85, 165], [90, 95, 185]]]</td>\n",
       "      <td>[[100.68982, 106.199, 204.83968]]</td>\n",
       "      <td>0.6464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multiple Parallel Input and Multi-Step Output</th>\n",
       "      <td>Multivariate Multi-Step LSTM Models</td>\n",
       "      <td>[rows, columns]</td>\n",
       "      <td>[[[60, 65, 125], [70, 75, 145], [80, 85, 165]]]</td>\n",
       "      <td>[[[90.265816, 95.88, 185.84712], [100.86708, 105.51342, 206.3824]]]</td>\n",
       "      <td>0.7482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vanilla LSTM</th>\n",
       "      <td>Univariate LSTM Models</td>\n",
       "      <td>[samples, timesteps, features]</td>\n",
       "      <td>[[[70], [80], [90]]]</td>\n",
       "      <td>[[101.01401]]</td>\n",
       "      <td>1.0282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN LSTM</th>\n",
       "      <td>Univariate LSTM Models</td>\n",
       "      <td>[samples, subsequences, timesteps, features]</td>\n",
       "      <td>[[[[60], [70]], [[80], [90]]]]</td>\n",
       "      <td>[[101.11435]]</td>\n",
       "      <td>1.2418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multiple Input Multi-Step Output</th>\n",
       "      <td>Multivariate Multi-Step LSTM Models</td>\n",
       "      <td>[rows, columns]</td>\n",
       "      <td>[[[70, 75], [80, 85], [90, 95]]]</td>\n",
       "      <td>[[186.0647, 206.36623]]</td>\n",
       "      <td>1.5001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Encoder-Decoder</th>\n",
       "      <td>Multi-Step LSTM Models</td>\n",
       "      <td>[samples, timesteps, features]</td>\n",
       "      <td>[[[70], [80], [90]]]</td>\n",
       "      <td>[[[101.36606], [114.12388]]]</td>\n",
       "      <td>9.4362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacked LSTM</th>\n",
       "      <td>Univariate LSTM Models</td>\n",
       "      <td>[samples, timesteps, features]</td>\n",
       "      <td>[[[70], [80], [90]]]</td>\n",
       "      <td>[[103.255325]]</td>\n",
       "      <td>10.5971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ConvLSTM</th>\n",
       "      <td>Univariate LSTM Models</td>\n",
       "      <td>[samples, timesteps, rows, columns, features]</td>\n",
       "      <td>[[[[[60]\\n [70]]], [[[80]\\n [90]]]]]</td>\n",
       "      <td>[[104.403595]]</td>\n",
       "      <td>19.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vector Output</th>\n",
       "      <td>Multi-Step LSTM Models</td>\n",
       "      <td>[samples, timesteps, features]</td>\n",
       "      <td>[[[70], [80], [90]]]</td>\n",
       "      <td>[[104.01215, 116.03949]]</td>\n",
       "      <td>26.2864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              type  \\\n",
       "model                                                                                \n",
       "Bidirectional LSTM                                          Univariate LSTM Models   \n",
       "Multiple Input Series                                     Multivariate LSTM Models   \n",
       "Multiple Parallel Series                                  Multivariate LSTM Models   \n",
       "Multiple Parallel Input and Multi-Step Output  Multivariate Multi-Step LSTM Models   \n",
       "Vanilla LSTM                                                Univariate LSTM Models   \n",
       "CNN LSTM                                                    Univariate LSTM Models   \n",
       "Multiple Input Multi-Step Output               Multivariate Multi-Step LSTM Models   \n",
       "Encoder-Decoder                                             Multi-Step LSTM Models   \n",
       "Stacked LSTM                                                Univariate LSTM Models   \n",
       "ConvLSTM                                                    Univariate LSTM Models   \n",
       "Vector Output                                               Multi-Step LSTM Models   \n",
       "\n",
       "                                                                                         dim  \\\n",
       "model                                                                                          \n",
       "Bidirectional LSTM                                            [samples, timesteps, features]   \n",
       "Multiple Input Series                                                        [rows, columns]   \n",
       "Multiple Parallel Series                                                     [rows, columns]   \n",
       "Multiple Parallel Input and Multi-Step Output                                [rows, columns]   \n",
       "Vanilla LSTM                                                  [samples, timesteps, features]   \n",
       "CNN LSTM                                        [samples, subsequences, timesteps, features]   \n",
       "Multiple Input Multi-Step Output                                             [rows, columns]   \n",
       "Encoder-Decoder                                               [samples, timesteps, features]   \n",
       "Stacked LSTM                                                  [samples, timesteps, features]   \n",
       "ConvLSTM                                       [samples, timesteps, rows, columns, features]   \n",
       "Vector Output                                                 [samples, timesteps, features]   \n",
       "\n",
       "                                                                                             X  \\\n",
       "model                                                                                            \n",
       "Bidirectional LSTM                                                        [[[70], [80], [90]]]   \n",
       "Multiple Input Series                                       [[[80, 85], [90, 95], [100, 105]]]   \n",
       "Multiple Parallel Series                       [[[70, 75, 145], [80, 85, 165], [90, 95, 185]]]   \n",
       "Multiple Parallel Input and Multi-Step Output  [[[60, 65, 125], [70, 75, 145], [80, 85, 165]]]   \n",
       "Vanilla LSTM                                                              [[[70], [80], [90]]]   \n",
       "CNN LSTM                                                        [[[[60], [70]], [[80], [90]]]]   \n",
       "Multiple Input Multi-Step Output                              [[[70, 75], [80, 85], [90, 95]]]   \n",
       "Encoder-Decoder                                                           [[[70], [80], [90]]]   \n",
       "Stacked LSTM                                                              [[[70], [80], [90]]]   \n",
       "ConvLSTM                                                  [[[[[60]\\n [70]]], [[[80]\\n [90]]]]]   \n",
       "Vector Output                                                             [[[70], [80], [90]]]   \n",
       "\n",
       "                                                                                                                 y  \\\n",
       "model                                                                                                                \n",
       "Bidirectional LSTM                                                                                   [[100.12335]]   \n",
       "Multiple Input Series                                                                                [[205.16708]]   \n",
       "Multiple Parallel Series                                                         [[100.68982, 106.199, 204.83968]]   \n",
       "Multiple Parallel Input and Multi-Step Output  [[[90.265816, 95.88, 185.84712], [100.86708, 105.51342, 206.3824]]]   \n",
       "Vanilla LSTM                                                                                         [[101.01401]]   \n",
       "CNN LSTM                                                                                             [[101.11435]]   \n",
       "Multiple Input Multi-Step Output                                                           [[186.0647, 206.36623]]   \n",
       "Encoder-Decoder                                                                       [[[101.36606], [114.12388]]]   \n",
       "Stacked LSTM                                                                                        [[103.255325]]   \n",
       "ConvLSTM                                                                                            [[104.403595]]   \n",
       "Vector Output                                                                             [[104.01215, 116.03949]]   \n",
       "\n",
       "                                                   mse  \n",
       "model                                                   \n",
       "Bidirectional LSTM                              0.0152  \n",
       "Multiple Input Series                           0.0279  \n",
       "Multiple Parallel Series                        0.6464  \n",
       "Multiple Parallel Input and Multi-Step Output   0.7482  \n",
       "Vanilla LSTM                                    1.0282  \n",
       "CNN LSTM                                        1.2418  \n",
       "Multiple Input Multi-Step Output                1.5001  \n",
       "Encoder-Decoder                                 9.4362  \n",
       "Stacked LSTM                                   10.5971  \n",
       "ConvLSTM                                       19.3916  \n",
       "Vector Output                                  26.2864  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_df = pd.DataFrame(compare_list, columns=[\"type\",\"model\",\"dim\", \"X\",\"y\", \"mse\"])\n",
    "compare_df = compare_df.set_index(\"model\")\n",
    "compare_df['mse'] = compare_df['mse'].astype(float)\n",
    "compare_df = compare_df.sort_values('mse', ascending=True)\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10175fc8-d83d-4ce4-b32f-8beb1131b7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='model'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_df['mse'].plot.bar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
